---
title: "Machine Learning Assignment"

output: html_document
---
#### Executive Summary
The intent of this assignment is look at the data collected from a group of people who are part of the quantified self movement. Using this data, a model was created to predict what activity each member whose data was collected is performing. This model was then used to predict results for 20 test cases provided. A simple Random Forest model with three folds of data, repeated twice gave a model with 97.9 % accuracy. This then when tested against the test data gave all accurate results. Hence the model was not further fine tuned. 
The process of arriving at the model, its accuracy, out of sample error and prediction results are detailed in this assignment. 

#### Data Exploration

Reading the files. After initial read there were many observations which are either "NA" or had no value. Since neither will add any value to the model,  changed both values to be interpreted as "NA" at the time of read. This is then later used to remove columns which  are predominantly "NA".

```{r}
library(caret)
train <- read.csv("./Machine/data/pml-training.csv", header = TRUE, na.strings = c("NA", ""))
test <- read.csv("./Machine/data/pml-testing.csv", header =TRUE, na.strings=c("NA",""))
```

In this section we draw a basic exploratory graph to find if ignoring NA rows  retains the original data file's distribution for "classe".

```{r, echo=TRUE}
smallTrain <- na.omit(train)
dim(train)
dim(smallTrain)
par(mfrow=c(1,2))
plot(train$user_name, train$classe)
plot(smallTrain$user_name, smallTrain$classe)

```

Eliminating NA observations reduces the size of the new dataset to approximately  less than 5 percent of the original dataset. From the explorative graph it is also clear that the small set is not representative of the original data. Considering that there are many columns that are mostly NA's,ignoring them is more likely to give us a more robust model. The approach used for cleaning the data is

1. Use colSums to elimate NA or "" columns 
2. Eliminate the first seven columns as they are seq no,  user name,additive variables, timestamp and two flags with little change in values
3. Split the data into a training dataset tTrain ( 70% of training) and validation dataset vTrain (30% or training)

```{r, echo=TRUE}
naCols <- colSums(is.na(train))
train <- train[, naCols == 0]
test <- test[, naCols == 0]
train <- train[-c(1,2,3,4,5,6,7)]
test <- test[-c(1,2,3,4,5,6,7)]

dim(train)
dim(test)

inTrain <- createDataPartition(y=train$classe,p=0.7, list=FALSE)
tTrain <- train[inTrain,]
vTrain <- train[-inTrain,]

```

#### Model creation
We will start with a principle component analysis to identify the variables contributing maximum to the variance. We will use a high cut-off of 99%.  The variables accounting for the most variability can be seen in this plot. We then use the preProc object obtained from the PCA for our model training and creation.

```{r, echo=TRUE}
preProc <- preProcess(tTrain[, -53], method = "pca", thresh = 0.99)
trainPC <- predict(preProc, tTrain[, -53])
validPC <- predict(preProc, vTrain[, -53])

tControl <- trainControl(method = "cv", number = 3, repeats = 2)
modelFit <- train(tTrain$classe ~ ., method = "rf", data = trainPC, trControl=tControl, importance = TRUE)
modelFit

par(mfrow=c(1,2))
varImpPlot(modelFit$finalModel, main = "Principal  components by importance")


prfValid <- predict(modelFit, validPC)
confusionMatrix(prfValid, vTrain$classe)

postResample(prfValid, vTrain$classe)

```
The model is reasonably accurate at 97.9 % . We will test the final outcome using this model. You will find later that this model predicts all 20 test cases accurately. No further model fine tuning was done for the purpose of this test.

The out of sample error rate(1-Accuracy) for this model  is fairly accurate as well and is 

```{r, echo=TRUE}
1-postResample(prfValid, vTrain$classe)[[1]]
```

####Predicted Results

```{r, echo=TRUE}
testPC <- predict(preProc, test[, -53])
prfTest <- predict(modelFit, testPC)
test$classe<- prfTest
test[c("problem_id","classe")]
```
